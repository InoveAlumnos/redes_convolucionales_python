{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67RBrvkUviuj"
   },
   "source": [
    "<a href=\"https://www.inove.com.ar\"><img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/PA%20Banner.png\" width=\"1000\" align=\"center\"></a>\n",
    "\n",
    "\n",
    "# Ejercicio de clasificación con redes neuronales convolucionales (CNN)\n",
    "\n",
    "Ejemplo de clasificación utilizando redes neuronales convolucionales para la clasificación de imagenes<br>\n",
    "\n",
    "v2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwM2OMhpmKRa"
   },
   "source": [
    "### **Objetivos:**\n",
    "* Estudiar el dataset de los Simpsons.\n",
    "* Visualizar las imágenes a analizar.\n",
    "* Normalizar la imágenes de train.\n",
    "* Construir, entrenar y evaluar dos modelos con Redes Convolucionales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y2sSeyEovSw-"
   },
   "outputs": [],
   "source": [
    "#Librerias a implementar\n",
    "import os\n",
    "import platform\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "#from keras.utils import to_categorical\n",
    "from keras.utils.np_utils import to_categorical # Si esto no funciona, probar con el import anterior\n",
    "\n",
    "from glob import glob\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Szo7P_3v00C"
   },
   "source": [
    "# Recolectar datos\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline1.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbNSgxdfw0ix"
   },
   "source": [
    "### `Simpsons dataset`:\n",
    "El dataset **`Simpsons`** contiene 550Mbytes de imagenes a color de los personajes de los Simpsons (47 personajes). Cada imagen es de tiene al rededor de 500x450 píxeles a color (3 canales).<br> [Dataset source](https://www.kaggle.com/paultimothymooney/zipfiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZCrQUTBmdSc"
   },
   "source": [
    "## Código de descarga del dataset Simpsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NOd5sxxNlerE"
   },
   "outputs": [],
   "source": [
    "# Descargar la carpeta imagenes simpsons\n",
    "if os.access('./simpsons_dataset', os.F_OK) is False:\n",
    "    !curl -L -o 'simpsons_dataset.zip' 'https://drive.google.com/u/0/uc?id=1mn7cuJ4VudbF1HshbWnvsivSk5o8qAn2&export=download&confirm=t'\n",
    "    !unzip -q simpsons_dataset.zip\n",
    "else:\n",
    "    print(\"La carpeta ya se encuentra descargada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "39D74GHn9hi1"
   },
   "outputs": [],
   "source": [
    "# Visualizar los directiorios o tipos de personas\n",
    "# os, módulo \"sistema operativo\"\n",
    "# .listdir, método que permite listar el contenido dentro de una carpeta\n",
    "# Dentro de la carpeta simpsons_dataset, cada personaje tiene su propia carpeta de imágenes.\n",
    "os.listdir(\"./simpsons_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ywRZdgPa97sk"
   },
   "outputs": [],
   "source": [
    "# Se almacena todas las carpetas en la variable \"personajes\"\n",
    "personajes = os.listdir(\"./simpsons_dataset\")\n",
    "\n",
    "# Con la función len() se puede saber la cantidadde carpetas. \n",
    "print(\"Cantidad de tipos de personaejs:\", len(personajes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mInVOZQvolzM"
   },
   "outputs": [],
   "source": [
    "# Visualizar las 10 primeras imagenes de un personaje\n",
    "# glob(), encuentra todos los nombres de rutas que se asemejan a un patrón especificado de acuerdo a las reglas que se siguen.\n",
    "files = glob(\"./simpsons_dataset/\" + personajes[0] + \"/**.jpg\")\n",
    "\n",
    "# plt alias de Matplotlib.\n",
    "# Método figure() crea el espacio para dibujar.\n",
    "# Con figsize=(16,9) se define el ancho y alto del dibujo\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "\n",
    "# Bucle que itera 10 veces para mostrar las primeras 10 imágenes del dataset\n",
    "for i in range(10):\n",
    "    \n",
    "    # ax gráfico que mostrará las imágenes en 2 filas y 5 columnas\n",
    "    # En cada iteración va ubicando la imagen en la siguiente posición (i+1)\n",
    "    ax = fig.add_subplot(2, 5, i+1)\n",
    "    \n",
    "    # .axis('off') elimina el recuadro de cada imagen\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Herramienta de Matplotlib para para leer imágenes\n",
    "    img = mpimg.imread(files[i])\n",
    "\n",
    "    # Muestra las 50 imágenes de la variable data_X_train en el espacio del dibujo\n",
    "    plt.imshow(img)\n",
    "\n",
    "# Muestra la figura\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fYGanqnC_Ppw"
   },
   "outputs": [],
   "source": [
    "# Visualizar la dimension de la primera imagen\n",
    "img = mpimg.imread(files[0])\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "syeZ_UKH_Wsm"
   },
   "outputs": [],
   "source": [
    "# Visualizar como están representados los pixeles internos.\n",
    "print(img[85, 100:110, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xF62E6R5_lDh"
   },
   "source": [
    "#### Conclusiones\n",
    "- Las imagenes tienen tamaño variable, utilizaremos un tamaño reducido para que todas las imagenes sean iguales (se elije 150x150)\n",
    "- Las imagenes están representadas de 0 a 255, hay que normalizarlas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7kjz9KWqcij"
   },
   "source": [
    "## Código de descarga del dataset Simpsons para test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4_NjEA__fLBk"
   },
   "outputs": [],
   "source": [
    "# Descargar datos de test\n",
    "if os.access('simpsons_test', os.F_OK) is False:\n",
    "    if os.access('simpsons_test.zip', os.F_OK) is False:\n",
    "        if platform.system() == 'Windows':\n",
    "            !curl https://github.com/InoveAlumnos/dataset_analytics_python/raw/master/simpsons_test.zip > simpsons_test.zip\n",
    "        else:\n",
    "            !wget simpsons_test.zip https://github.com/InoveAlumnos/dataset_analytics_python/raw/master/simpsons_test.zip\n",
    "    !unzip -q simpsons_test.zip\n",
    "else:\n",
    "    print(\"El archivo ya se encuentra descargado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHHsGe1Qypde"
   },
   "source": [
    "# Procesar datos\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline2.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uvzaKBMbyoiy"
   },
   "outputs": [],
   "source": [
    "# Se importa ImageDataGenerator del módulo de keras.preprocessing.image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Crear un generador, indicando si deseamos realizar un escalado de la imagen\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# El método .flow_from_directory, toma la ruta a un directorio y genera lotes de datos aumentados.\n",
    "# target_size, se indica la dimensión de la imagen que se desea.\n",
    "# batch_size, la cantidad que va a tomar para aplicar la operación de escalado.\n",
    "# class_mode, es categorical ya que son varios personajes.\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        directory=\"./simpsons_dataset\",\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode=\"categorical\")\n",
    "\n",
    "# Con dict, arma un diccionario\n",
    "# con zip, es una función toma que iterables como argumentos y devuelve un iterador.\n",
    "# Es decir, se construye en diccionario indice:valor --> ubicacion:nombre_personaje\n",
    "index_to_classes = dict(zip(train_generator.class_indices.values(), train_generator.class_indices.keys()))\n",
    "index_to_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BnzYdlRzBxz"
   },
   "source": [
    "# Explorar datos\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline3.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vV05awstE6RX"
   },
   "outputs": [],
   "source": [
    "# El generador \"train_generator\" se lo puede utilizar para acceder a los datos\n",
    "# de a cantidad batch de imagenes. En este caso el generador me retornará\n",
    "# la primera vez las primeras 20 imágenes\n",
    "# El generador devuelve las imagenes (X) y las clases(personajes) a las que\n",
    "# pertenece (y)\n",
    "# X, y = train_generator.next()\n",
    "batch_imagenes, batch_clases = train_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H9jbktbPF7u3"
   },
   "outputs": [],
   "source": [
    "# Cantidad de imágenes, dimensión alto, dimensión ancho, canales de color\n",
    "batch_imagenes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KmdCnAQ2Kd7x"
   },
   "outputs": [],
   "source": [
    "# Cantidad de imágenes categorías (representadas por cada personaje)\n",
    "batch_clases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vGCIcOPSGSk1"
   },
   "outputs": [],
   "source": [
    "# Cantidad de imágenes.\n",
    "print(\"Cantidad de imagenes en el batch:\", batch_imagenes.shape[0])\n",
    "\n",
    "# Dimensión alto, dimensión ancho, canales de color\n",
    "print(\"Dimensión de la imagen:\", batch_imagenes.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u_jnc_dqKgCt"
   },
   "outputs": [],
   "source": [
    "# batch_clases, variable que contiene la cantidad de personajes.\n",
    "print(\"Cantidad de clases/personajes:\", batch_clases.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dUbEzgZsGfDB"
   },
   "outputs": [],
   "source": [
    "# plt alias de Matplotlib.\n",
    "# Método figure() crea el espacio para dibujar.\n",
    "# Con figsize=(16,9) se define el ancho y alto del dibujofig = plt.figure(figsize=(16,9))\n",
    "# Observar las primeras 5 imagenes de ese batch\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "\n",
    "# Itera 5 veces\n",
    "for i in range(5):\n",
    "\n",
    "    # ax, gráfico que mostrará las imágenes en 1 filas y 5 columnas\n",
    "    # En cada iteración va ubicando la imagen en la siguiente posición (i+1)\n",
    "    ax = fig.add_subplot(1, 5, i+1)\n",
    "\n",
    "    # Muestra la imagen\n",
    "    ax.imshow(batch_imagenes[i])\n",
    "\n",
    "    # Ubica por la posición de la imagen el nombre que le corresponde.\n",
    "    numero_clase = batch_clases[i].argmax()\n",
    "\n",
    "    # A cada imagen le agrega un titulo que sería el nombre del personaje que le corresponde.\n",
    "    ax.set_title(index_to_classes[numero_clase])\n",
    "\n",
    "# Muestra la imagen.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmZRSSv1JPMz"
   },
   "source": [
    "__Importante__! Luego de usar un generador \"jugando\", ese batch de imagenes que sacamos ya no se encontrará disponible para ser utilizado en el entrenamiento, es recomendable volver a crear los generadores si se los consumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wt_1BC0cKEcz"
   },
   "outputs": [],
   "source": [
    "# Crear un generador, indicando para realizar un escalado de la imagen\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# El método .flow_from_directory, toma la ruta a un directorio y genera lotes de datos aumentados.\n",
    "# target_size, se indica la dimensión de la imagen que se desea.\n",
    "# batch_size, la cantidad que va a tomar para aplicar la operación de escalado.\n",
    "# class_mode, es categorical ya que son varios personajes.\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        directory=\"./simpsons_dataset\",\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode=\"categorical\")\n",
    "\n",
    "# Con dict, arma un diccionario\n",
    "# con zip, es una función toma que iterables como argumentos y devuelve un iterador.\n",
    "# Es decir, se construye en diccionario indice:valor --> ubicacion:nombre_personaje\n",
    "index_to_classes = dict(zip(train_generator.class_indices.values(), train_generator.class_indices.keys()))\n",
    "index_to_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5K8xTSRmyQCD"
   },
   "source": [
    "### Importante: Los generadores ya que encargan de transformar la salida a oneHotEncoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7z_SuZlj3gbQ"
   },
   "source": [
    "# Entrenar modelo\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline4.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Wb3oMvn-mIF"
   },
   "outputs": [],
   "source": [
    "# input shape (observado del análisis de datos)\n",
    "# Almacena las dimensiones y los canales de color, sería la entrada a la red\n",
    "in_shape = (150, 150, 3)\n",
    "in_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wpYcXh1g_N3Q"
   },
   "outputs": [],
   "source": [
    "# output shape (observado del análisis de datos)\n",
    "# 42 ya que representa categorías, los nombres de los personajes con lo que se entrena la red\n",
    "out_shape = 42\n",
    "out_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7MEiMyVy1GD"
   },
   "source": [
    "### Debemos definir cuantas imagenes se consumiran por epoca (steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pQ8tQk2DMgBd"
   },
   "outputs": [],
   "source": [
    "# ya que estando el generador en el medio Keras no puede saberlo por\n",
    "# su cuenta\n",
    "steps_per_epoch_train = len(train_generator)\n",
    "steps_per_epoch_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WoPKBgrKYh3F"
   },
   "outputs": [],
   "source": [
    "# Se importa Dense,  Dropout, Flatten de la librería keras.layers\n",
    "# Se importa Conv2D, MaxPooling2D  de la librería keras.layers.convolutional\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "\n",
    "# Se crea el objeto model1 a partir de la clase Sequential()\n",
    "model1 = Sequential()\n",
    "\n",
    "# Primero realizaremos un modelo muy simple con una solo par de CONV + POOL\n",
    "# tal cual se utilizo en los otros notebooks de dataset más simples\n",
    "\n",
    "# .add, método para agregar capas en la red\n",
    "# Conv2D, agrega una capa convolucional, cuyos parámetros son:\n",
    "#filters, cantidad de filtros \n",
    "# kernel_size,  especifica la altura y el ancho de la ventana de convolución 2D\n",
    "# strides, especifica las zancadas (de cuánto en cuánto) de la convolución a lo largo de la altura y el ancho.\n",
    "# MaxPooling2D, achica la imagen.\n",
    "model1.add(Conv2D(filters=8, kernel_size=(5, 5), strides=(1, 1), padding='same', activation='relu', input_shape=in_shape))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# Capa de comunicación entre la red convolucional y la red neuronal\n",
    "model1.add(Flatten())\n",
    "\n",
    "# Red Neuronal\n",
    "model1.add(Dense(units=64, activation='relu'))\n",
    "\n",
    "# Capa de salida.\n",
    "model1.add(Dense(units=out_shape, activation='softmax'))\n",
    "\n",
    "# Configuración del modelo para el entrenamiento, implementando el método compile a partir del modelo creado.\n",
    "# Se necesita indicar los parámetros:\n",
    "# optimizer, nombre del optimizador (es el algoritmo que se encarga del descenso de gradiente estocástico)\n",
    "# Fuente: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\n",
    "# loss, se llama función de pérdida, representa las categorías conocidas de las predicción. Al ser 'categorical_crossentropy' \n",
    "#la predicción tiene una salida con varias opciones.\n",
    "# metrics, se define la métrica que evaluará el modelo durante el entrenamiento y las pruebas.\n",
    "model1.compile(optimizer=\"Adam\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Resumen de la estructura de la red.\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GT_IpBOkYyor"
   },
   "source": [
    "Se puede observar que esta red tiene más de 2 millones de parámetros para entrenar!!\\\n",
    "Esto es porque la capa densa de POOL de 75x75x8 se transforma a un flatten\n",
    "de 450000 neuronaes (75x75x8 = 45000) que luego se conectan con todas las \n",
    "neuroanes de la capa sigueinte (64) --> 45000x64 + 64 = 2880064\\\n",
    "**NOTA:** Para bajar la cantidad de parametros debemos seguir comprimiendo la imagen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I-d7Yw_aYsM0"
   },
   "outputs": [],
   "source": [
    "# Se entrena el modelo con el método fit\n",
    "# Necesita definir los valores para train_generator, la cantidad de épocas que seria la iteraciones de entrenamiento y\n",
    "#  steps_per_epoch, cantidad de imágenes a consumir la red por época.\n",
    "history1 = model1.fit(train_generator, steps_per_epoch=steps_per_epoch_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lhf9z3PkYuog"
   },
   "outputs": [],
   "source": [
    "# Variable epoch_count, que almacena en una lista la cantidad de épocas de train\n",
    "# history1, es la variable que almacena las predicciones del modelo\n",
    "# y de ella, se puede acceder a información como su historial (history) del accuracy\n",
    "epoch_count = range(1, len(history1.history['accuracy']) + 1)\n",
    "\n",
    "# De Seaborn (sns) se accede al gráfico de línea para representar el 'accuracy'.\n",
    "sns.lineplot(x=epoch_count,  y=history1.history['accuracy'], label='train')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fu1u9JhXq9Dy"
   },
   "outputs": [],
   "source": [
    "# Se importa Dense,  Dropout, Flatten de la librería keras.layers\n",
    "# Se importa Conv2D, MaxPooling2D  de la librería keras.layers.convolutional\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "\n",
    "# Se crea el objeto model2 a partir de la clase Sequential()\n",
    "model2 = Sequential()\n",
    "\n",
    "# Ahora agregaremos más pares de capas CONV + POOL a fin de reducir más la\n",
    "# dimensión de la imagen antes de llegar a la capa flatten\n",
    "# Otra estrategia es ir aumentando la cantidad de filtros a medida que crece\n",
    "# la profundidad de la red\n",
    "\n",
    "# convolucional f=(3,3), # de filtros: 8, activación relu\n",
    "# max pooling f=2, s=2\n",
    "model2.add(Conv2D(filters = 8, kernel_size = (3, 3), strides=1, padding='same', activation='relu', input_shape=(150, 150, 3)))\n",
    "model2.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n",
    "# convolucional f=(3,3), # de filtros: 16, activación relu\n",
    "# max pooling f=2, s=2\n",
    "model2.add(Conv2D(filters = 16, kernel_size = (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "# convolucional f=(3,3), # de filtros: 32, activación relu\n",
    "# max pooling f=2, s=2\n",
    "model2.add(Conv2D(filters = 32, kernel_size = (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "# convolucional f=(3,3), # de filtros: 64, activación relu\n",
    "# max pooling f=2, s=2\n",
    "model2.add(Conv2D(filters = 64, kernel_size = (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "# capa flatten\n",
    "model2.add(Flatten())\n",
    "# capa densa de 64 elementos activación relu\n",
    "model2.add(Dense(units=128, activation='relu'))\n",
    "model2.add(Dropout(rate=0.2))\n",
    "# capa densa con un output de 10 elemento con activación softmax\n",
    "model2.add(Dense(units=out_shape, activation='softmax'))\n",
    "\n",
    "# Configuración del modelo para el entrenamiento, implementando el método compile a partir del modelo creado.\n",
    "# Se necesita indicar los parámetros:\n",
    "# optimizer, nombre del optimizador (es el algoritmo que se encarga del descenso de gradiente estocástico)\n",
    "# Fuente: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\n",
    "# loss, se llama función de pérdida, representa las categorías conocidas de las predicción. Al ser 'categorical_crossentropy' \n",
    "#la predicción tiene una salida con varias opciones.\n",
    "# metrics, se define la métrica que evaluará el modelo durante el entrenamiento y las pruebas.\n",
    "model2.compile(optimizer=\"Adam\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Resumen de la estructura de la red.\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J_89g3dSm2wf"
   },
   "outputs": [],
   "source": [
    "# Se entrena el modelo con el método fit\n",
    "# Necesita definir los valores para train_generator, la cantidad de épocas que seria la iteraciones de entrenamiento y\n",
    "#  steps_per_epoch, cantidad de imágenes a consumir la red por época.\n",
    "history2 = model2.fit(train_generator, steps_per_epoch=steps_per_epoch_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xDuagYJHvNlm"
   },
   "outputs": [],
   "source": [
    "# Variable epoch_count, que almacena en una lista la cantidad de épocas de train\n",
    "# history2, es la variable que almacena las predicciones del modelo\n",
    "# y de ella, se puede acceder a información como su historial (history) del accuracy\n",
    "epoch_count = range(1, len(history2.history['accuracy']) + 1)\n",
    "\n",
    "# De Seaborn (sns) se accede al gráfico de línea para representar el 'accuracy'.\n",
    "sns.lineplot(x=epoch_count,  y=history2.history['accuracy'], label='train')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EsH5q9y6Qt1-"
   },
   "outputs": [],
   "source": [
    "# Crear un generador, indicando para realizar un escalado de la imagen\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# El método .flow_from_directory, toma la ruta a un directorio y genera lotes de datos aumentados.\n",
    "# target_size, se indica la dimensión de la imagen que se desea.\n",
    "# batch_size, la cantidad que va a tomar para aplicar la operación de escalado.\n",
    "# class_mode, es categorical ya que son varios personajes.\n",
    "# shuffle, sin desordenar\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        directory=\"./simpsons_test\",\n",
    "        target_size=(150, 150),\n",
    "        batch_size=10,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "\n",
    "\n",
    "# Predecir los datos a partir de los datos de test (test_generator)\n",
    "y_hat_prob = model2.predict(test_generator)\n",
    "\n",
    "# Resultado de la predicción de la primer imagen.\n",
    "# Muestra las probabilidades para cada personaje.\n",
    "# La probabilidad más alta es la predicción.\n",
    "y_hat_prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qxs4EZSBAZoh"
   },
   "outputs": [],
   "source": [
    "# Para la probabilidad de la primer imagen, se ubica su ubicación (Pero no tenemos el nombre del personaje)\n",
    "y_hat = np.argmax(y_hat_prob,axis=1)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKdnAVO05pY7"
   },
   "source": [
    "## ¿Cómo obtener el nombre del personaje de la predicción?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iBqoGBsIS4Rr"
   },
   "outputs": [],
   "source": [
    "#¿Cómo obtenemos el \"y\" verdadero?\n",
    "# A partir del atributo filanames\n",
    "test_generator.filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-zSHo8N7jMA"
   },
   "source": [
    "#### **Nota:** Los nombres de los personajes de test_generator.filenames tienen barra, extensiones. Por lo que, hay que extraer solo el nombre.\n",
    "Ejemplo: \n",
    "\n",
    "\n",
    "*   De esto --> ['test_images/sideshow_bob_38.jpg']\n",
    "*   A esto --> [sideshow_bob]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AaIy0eJFS_bn"
   },
   "outputs": [],
   "source": [
    "# Muy rebuscada esta forma de obtener los nombres de los personajes!\n",
    "# Pero en general cuando tenemos los datos de test no tenemos los nombres\n",
    "# por lo que no tenemos el \"y\" verdadero\n",
    "\n",
    "personajes_test = []\n",
    "\n",
    "# Bucle que recorre todos los nombres de los personajes de test_generator\n",
    "# Para extraer sólo el nombre\n",
    "for file in test_generator.filenames:\n",
    "\n",
    "    # Ubica la ruta del archivo y alamcena solo el nombre, \n",
    "    # por ejemplo: abraham_grampa_simpson_39.jpg\n",
    "    image_name = os.path.basename(file)\n",
    "    \n",
    "    # Una vez ubicado el nombre de la img,\n",
    "    # separa los elementos por \"_\", por ejemplo; ['abraham', 'grampa', 'simpson', '39.jpg']\n",
    "    image_name_split = image_name.split(\"_\")\n",
    "    \n",
    "    # Extrae el último elemento que corresponde a la extensión de la imagen,\n",
    "    # por ejemplo; ['abraham', 'grampa', 'simpson']\n",
    "    personaje_name_split = image_name_split[:len(image_name_split)-1]\n",
    "   \n",
    "    # Nos quedamos con el primer elemento, primer nombre de la lista,\n",
    "    # por ejemplo; abraham\n",
    "    personaje = personaje_name_split[0]\n",
    "  \n",
    "    # Bucle que recorre la lista con el nombre del personaje\n",
    "    # desde el primer elemento hasta el final, por ejemplo; ['abraham', 'grampa', 'simpson']\n",
    "    # Para concatenar el nombre con \"_\"\n",
    "    for name in personaje_name_split[1:]:\n",
    "        personaje += \"_\" + name\n",
    "        \n",
    "    # Agrega el nombre del personaje en una lista \n",
    "    personajes_test.append(personaje)\n",
    "personajes_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZXET42yAUmj"
   },
   "outputs": [],
   "source": [
    "# Obtener el \"y\" verdadero\n",
    "# por cada personaje de la predicción ubica el indice \n",
    "# que le corresponde en los datos de train_generator \n",
    "y_test = [train_generator.class_indices[personaje] for personaje in personajes_test]\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ww_S7M1lw9oT"
   },
   "outputs": [],
   "source": [
    "# Descargar el modelo entrenado para usar en el futuro sin tener\n",
    "# que volver a entrenarlo\n",
    "model2.save(\"cnn_simpsons.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3IfjUuI4XnD"
   },
   "source": [
    "# Validar modelo\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline5.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HnXeXHwdyHVx"
   },
   "outputs": [],
   "source": [
    "# Calcular la exactitud (accuracy)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TeLeYLYz6ZhO"
   },
   "outputs": [],
   "source": [
    "# Se utiliza la matriz de confusión para evaluar la precisión de una clasificación.\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Necesita dos variables que contengan los valores a comparar\n",
    "cm = confusion_matrix(y_test, y_hat)\n",
    "\n",
    "# Código para realizar la representación gráfica con los resultados\n",
    "# Se crea la varible cmd, que almacena visualization de la Confusion Matrix \n",
    "# Necesita la variable cm que contiene los resultados de la comparación entre los valores reales y predicción\n",
    "# display_labels, se especifica las etiquetas de las categorias que se evalúan.\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=list(range(47)))\n",
    "\n",
    "# Con cmd.plot se especifica el mapa de colores reconocido por matplotlib.\n",
    "cmd.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "# Mostrar la figura\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dZxGbjG96jR"
   },
   "source": [
    "# Utilizar modelo\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline6.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oj5uKlZ9BGUT"
   },
   "source": [
    "### Observar los resultados de la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "noOsuU6Tb4GZ"
   },
   "outputs": [],
   "source": [
    "#  test_generator.next(), para observar los resultados de las siguientes 10 imágenes de la predección.\n",
    "batch_test = test_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cefy3ktFb6j6"
   },
   "outputs": [],
   "source": [
    "# plt alias de Matplotlib.\n",
    "# Método figure() crea el espacio para dibujar.\n",
    "# Con figsize=(16,9) se define el ancho y alto del dibujofig = plt.figure(figsize=(16,9))\n",
    "# Observar las primeras 5 imagenes de ese batch\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "\n",
    "# Itera 5 veces\n",
    "for i in range(10):\n",
    "\n",
    "    # ax, gráfico que mostrará las imágenes en 2 filas y 5 columnas\n",
    "    # En cada iteración va ubicando la imagen en la siguiente posición (i+1)\n",
    "    ax = fig.add_subplot(2, 5, i+1)\n",
    "\n",
    "    # Muestra la imagen\n",
    "    ax.imshow(batch_test[i])\n",
    "\n",
    "    # Ubica por la posición de la imagen el nombre que le corresponde.\n",
    "    numero_clase = y_hat[i]\n",
    "\n",
    "    # A cada imagen le agrega un titulo que sería el nombre del personaje que le corresponde.\n",
    "    ax.set_title(index_to_classes[numero_clase])\n",
    "\n",
    "# Muestra la imagen.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7yzVZcZ9-4m"
   },
   "source": [
    "# Conclusión\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline7.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWAReOgo-B7b"
   },
   "source": [
    "Al utilizar más pares de capas CONV+POOL se pudo obtener un mejor resultado, un modelo casi perfecto. Hay que tener en cuenta que el dataset de test es muy pequeño y hay muchos otros personajes que no estamos clasificando."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
