{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67RBrvkUviuj"
      },
      "source": [
        "<a href=\"https://www.inove.com.ar\"><img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/PA%20Banner.png\" width=\"1000\" align=\"center\"></a>\n",
        "\n",
        "\n",
        "# Ejercicio de clasificación con redes neuronales convolucionales (CNN)\n",
        "\n",
        "Ejemplo de clasificación utilizando redes neuronales convolucionales para la clasificación de imagenes<br>\n",
        "\n",
        "v1.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2sSeyEovSw-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import platform\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "#from keras.utils import to_categorical\n",
        "from keras.utils.np_utils import to_categorical # Si esto no funciona, probar con el import anterior\n",
        "\n",
        "from glob import glob\n",
        "import matplotlib.image as mpimg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Szo7P_3v00C"
      },
      "source": [
        "# Recolectar datos\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline1.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbNSgxdfw0ix"
      },
      "source": [
        "### `Simpsons dataset`:\n",
        "El dataset **`Simpsons`** contiene 550Mbytes de imagenes a color de los personajes de los Simpsons (47 personajes). Cada imagen es de tiene al rededor de 500x450 píxeles a color (3 canales).<br> [Dataset source](https://www.kaggle.com/paultimothymooney/zipfiles)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar la carpeta imagenes simpsons\n",
        "if os.access('./simpsons_dataset', os.F_OK) is False:\n",
        "    !curl -L -o 'simpsons_dataset.zip' 'https://drive.google.com/u/0/uc?id=1mn7cuJ4VudbF1HshbWnvsivSk5o8qAn2&export=download&confirm=t'\n",
        "    !unzip -q simpsons_dataset.zip\n",
        "else:\n",
        "    print(\"La carpeta ya se encuentra descargada\")"
      ],
      "metadata": {
        "id": "NOd5sxxNlerE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39D74GHn9hi1"
      },
      "outputs": [],
      "source": [
        "# Visualizar los directiorios o tipos de personas\n",
        "os.listdir(\"./simpsons_dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywRZdgPa97sk"
      },
      "outputs": [],
      "source": [
        "personajes = os.listdir(\"./simpsons_dataset\")\n",
        "print(\"Cantidad de tipos de personaejs:\", len(personajes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGbCJanFR8oL"
      },
      "outputs": [],
      "source": [
        "# Visualizar las 10 primeras imagenes de un personaje\n",
        "files = glob(\"./simpsons_dataset/\" + personajes[0] + \"/**.jpg\")\n",
        "\n",
        "fig = plt.figure(figsize=(16,9))\n",
        "for i in range(10):\n",
        "    ax = fig.add_subplot(2, 5, i+1)\n",
        "    ax.axis('off')\n",
        "    img = mpimg.imread(files[i])\n",
        "    plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYGanqnC_Ppw"
      },
      "outputs": [],
      "source": [
        "# Visualizar la dimension de la primera imagen\n",
        "img = mpimg.imread(files[0])\n",
        "img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syeZ_UKH_Wsm"
      },
      "outputs": [],
      "source": [
        "# Visualizar como están representados los pixeles\n",
        "print(img[85, 100:110, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xF62E6R5_lDh"
      },
      "source": [
        "#### Conclusiones\n",
        "- Las imagenes tienen tamaño variable, utilizaremos un tamaño reducido para que todas las imagenes sean iguales (se elije 150x150)\n",
        "- Las imagenes están representadas de 0 a 255, hay que normalizarlas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_NjEA__fLBk"
      },
      "outputs": [],
      "source": [
        "# Descargar datos de test\n",
        "if os.access('simpsons_test', os.F_OK) is False:\n",
        "    if os.access('simpsons_test.zip', os.F_OK) is False:\n",
        "        if platform.system() == 'Windows':\n",
        "            !curl https://github.com/InoveAlumnos/dataset_analytics_python/raw/master/simpsons_test.zip > simpsons_test.zip\n",
        "        else:\n",
        "            !wget simpsons_test.zip https://github.com/InoveAlumnos/dataset_analytics_python/raw/master/simpsons_test.zip\n",
        "    !unzip -q simpsons_test.zip\n",
        "else:\n",
        "    print(\"El archivo ya se encuentra descargado\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHHsGe1Qypde"
      },
      "source": [
        "# Procesar datos\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline2.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvzaKBMbyoiy"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Crear un generador, indicando si deseamos realizar un escalado de la imagen\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        directory=\"./simpsons_dataset\",\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode=\"categorical\")\n",
        "\n",
        "index_to_classes = dict(zip(train_generator.class_indices.values(), train_generator.class_indices.keys()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BnzYdlRzBxz"
      },
      "source": [
        "# Explorar datos\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline3.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vV05awstE6RX"
      },
      "outputs": [],
      "source": [
        "# El generador \"train_generator\" se lo puede utilizar para acceder a los datos\n",
        "# de a cantidad batch de imagenes. En este caso el generador me retornará\n",
        "# la primera vez las primeras 20 imagenes\n",
        "# El generador devuelve las imagenes (X) y las clases(personaes) a las que\n",
        "# pertenece (y)\n",
        "# X, y = train_generator.next()\n",
        "batch_imagenes, batch_clases = train_generator.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9jbktbPF7u3"
      },
      "outputs": [],
      "source": [
        "batch_imagenes.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmdCnAQ2Kd7x"
      },
      "outputs": [],
      "source": [
        "batch_clases.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGCIcOPSGSk1"
      },
      "outputs": [],
      "source": [
        "print(\"Cantidad de imagenes en el batch:\", batch_imagenes.shape[0])\n",
        "print(\"Dimensión de la imagen:\", batch_imagenes.shape[1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_jnc_dqKgCt"
      },
      "outputs": [],
      "source": [
        "print(\"Cantidad de clases/personajes:\", batch_clases.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUbEzgZsGfDB"
      },
      "outputs": [],
      "source": [
        "# Observar las primeras 5 imagenes de ese batch\n",
        "fig = plt.figure(figsize=(16,9))\n",
        "for i in range(5):\n",
        "    ax = fig.add_subplot(1, 5, i+1)\n",
        "    ax.imshow(batch_imagenes[i])\n",
        "    numero_clase = batch_clases[i].argmax()\n",
        "    ax.set_title(index_to_classes[numero_clase])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmZRSSv1JPMz"
      },
      "source": [
        "__Importante__! Luego de usar un generador \"jugando\", ese batch de imagenes que sacamos ya no se encontrará disponible para ser utilizado en el entrenamiento, es recomendable volver a crear los generadores si se los consumen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wt_1BC0cKEcz"
      },
      "outputs": [],
      "source": [
        "# Crear un generador, indicando si deseamos realizar un escalado de la imagen\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        directory=\"./simpsons_dataset\",\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode=\"categorical\")\n",
        "\n",
        "index_to_classes = dict(zip(train_generator.class_indices.values(), train_generator.class_indices.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z_SuZlj3gbQ"
      },
      "source": [
        "# Entrenar modelo\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline4.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vdIz9_r-sMe"
      },
      "outputs": [],
      "source": [
        "# Los generadores ya que encargan de transformar la salida a oneHotEncoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Wb3oMvn-mIF"
      },
      "outputs": [],
      "source": [
        "# input shape (observado del análisis de datos)\n",
        "in_shape = (150, 150, 3)\n",
        "in_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpYcXh1g_N3Q"
      },
      "outputs": [],
      "source": [
        "# output shape (observado del análisis de datos)\n",
        "out_shape = 42\n",
        "out_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQ8tQk2DMgBd"
      },
      "outputs": [],
      "source": [
        "# Debemos definir cuantas imagenes se consumiran por epoca (steps_per_epoch)\n",
        "# ya que estando el generador en el medio Keras no puede saberlo por\n",
        "# su cuenta\n",
        "steps_per_epoch_train = len(train_generator)\n",
        "steps_per_epoch_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoPKBgrKYh3F"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "\n",
        "model1 = Sequential()\n",
        "\n",
        "# Primero realizaremos un modelo muy simple con una solo par de CONV + POOL\n",
        "# tal cual se utilizo en los otros notebooks de dataset más simples\n",
        "\n",
        "model1.add(Conv2D(filters=8, kernel_size=(5, 5), strides=(1, 1), padding='same', activation='relu', input_shape=in_shape))\n",
        "model1.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(units=64, activation='relu'))\n",
        "model1.add(Dense(units=out_shape, activation='softmax'))\n",
        "\n",
        "model1.compile(optimizer=\"Adam\",\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT_IpBOkYyor"
      },
      "source": [
        "Se puede observar que esta red tiene más de 2 millones de parámetros para entrenar!!\\\n",
        "Esto es porque la capa densa de POOL de 75x75x8 se transforma a un flatten\n",
        "de 450000 neuronaes (75x75x8 = 45000) que luego se conectan con todas las \n",
        "neuroanes de la capa sigueinte (64) --> 45000x64 + 64 = 2880064\\\n",
        "Para bajar la cantidad de parametros debemos seguir comprimiendo la imagen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-d7Yw_aYsM0"
      },
      "outputs": [],
      "source": [
        "history1 = model1.fit(train_generator, steps_per_epoch=steps_per_epoch_train, epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhf9z3PkYuog"
      },
      "outputs": [],
      "source": [
        "epoch_count = range(1, len(history1.history['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history1.history['accuracy'], label='train')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu1u9JhXq9Dy"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "\n",
        "model2 = Sequential()\n",
        "\n",
        "# Ahora agregaremos más pares de capas CONV + POOL a fin de reducir más la\n",
        "# dimensión de la imagen antes de llegar a la capa flatten\n",
        "# Otra estrategia es ir aumentando la cantidad de filtros a medida que crece\n",
        "# la profundidad de la red\n",
        "\n",
        "# convolucional f=(3,3), # de filtros: 8, activación relu\n",
        "# max pooling f=2, s=2\n",
        "model2.add(Conv2D(filters = 8, kernel_size = (3, 3), strides=1, padding='same', activation='relu', input_shape=(150, 150, 3)))\n",
        "model2.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n",
        "# convolucional f=(3,3), # de filtros: 16, activación relu\n",
        "# max pooling f=2, s=2\n",
        "model2.add(Conv2D(filters = 16, kernel_size = (3, 3), strides=1, padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=2, strides=2))\n",
        "# convolucional f=(3,3), # de filtros: 32, activación relu\n",
        "# max pooling f=2, s=2\n",
        "model2.add(Conv2D(filters = 32, kernel_size = (3, 3), strides=1, padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=2, strides=2))\n",
        "# convolucional f=(3,3), # de filtros: 64, activación relu\n",
        "# max pooling f=2, s=2\n",
        "model2.add(Conv2D(filters = 64, kernel_size = (3, 3), strides=1, padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=2, strides=2))\n",
        "# capa flatten\n",
        "model2.add(Flatten())\n",
        "# capa densa de 64 elementos activación relu\n",
        "model2.add(Dense(units=128, activation='relu'))\n",
        "model2.add(Dropout(rate=0.2))\n",
        "# capa densa con un output de 10 elemento con activación softmax\n",
        "model2.add(Dense(units=out_shape, activation='softmax'))\n",
        "\n",
        "model2.compile(optimizer=\"Adam\",\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_89g3dSm2wf"
      },
      "outputs": [],
      "source": [
        "history2 = model2.fit(train_generator, steps_per_epoch=steps_per_epoch_train, epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDuagYJHvNlm"
      },
      "outputs": [],
      "source": [
        "epoch_count = range(1, len(history2.history['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history2.history['accuracy'], label='train')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsH5q9y6Qt1-"
      },
      "outputs": [],
      "source": [
        "# Predecir los datos\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        directory=\"./simpsons_test\",\n",
        "        target_size=(150, 150),\n",
        "        batch_size=10,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "\n",
        "y_hat_prob = model2.predict(test_generator)\n",
        "y_hat_prob[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxs4EZSBAZoh"
      },
      "outputs": [],
      "source": [
        "y_hat = np.argmax(y_hat_prob,axis=1)\n",
        "y_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBqoGBsIS4Rr"
      },
      "outputs": [],
      "source": [
        "#¿Cómo obtenemos el \"y\" verdadero?\n",
        "test_generator.filenames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaIy0eJFS_bn"
      },
      "outputs": [],
      "source": [
        "# Muy rebuscada esta forma de obtener los nombres de los personajes!\n",
        "# Pero en general cuando tenemos los datos de test no tenemos los nombres\n",
        "# por lo que no tenemos el \"y\" verdadero\n",
        "personajes_test = []\n",
        "for file in test_generator.filenames:\n",
        "    image_name = os.path.basename(file)\n",
        "    image_name_split = image_name.split(\"_\")\n",
        "    personaje_name_split = image_name_split[:len(image_name_split)-1]\n",
        "    personaje = personaje_name_split[0]\n",
        "    for name in personaje_name_split[1:]:\n",
        "        personaje += \"_\" + name\n",
        "    personajes_test.append(personaje)\n",
        "personajes_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUeviz_CUXlK"
      },
      "outputs": [],
      "source": [
        "# Obtener el \"y\" verdadero\n",
        "y_test = [train_generator.class_indices[personaje] for personaje in personajes_test]\n",
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ww_S7M1lw9oT"
      },
      "outputs": [],
      "source": [
        "# Descargar el modelo entrenado para usar en el futuro sin tener\n",
        "# que volver a entrenarlo\n",
        "model2.save(\"cnn_simpsons.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3IfjUuI4XnD"
      },
      "source": [
        "# Validar modelo\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline5.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnXeXHwdyHVx"
      },
      "outputs": [],
      "source": [
        "# Calcular la exactitud (accuracy)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeLeYLYz6ZhO"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "cm = confusion_matrix(y_test, y_hat)\n",
        "cmd = ConfusionMatrixDisplay(cm, display_labels=range(47))\n",
        "cmd.plot(cmap=plt.cm.Blues)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dZxGbjG96jR"
      },
      "source": [
        "# Utilizar modelo\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline6.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noOsuU6Tb4GZ"
      },
      "outputs": [],
      "source": [
        "batch_test = test_generator.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cefy3ktFb6j6"
      },
      "outputs": [],
      "source": [
        "# Observar las primeras 5 imagenes de ese batch\n",
        "fig = plt.figure(figsize=(16,9))\n",
        "for i in range(10):\n",
        "    ax = fig.add_subplot(2, 5, i+1)\n",
        "    ax.imshow(batch_test[i])\n",
        "    numero_clase = y_hat[i]\n",
        "    ax.set_title(index_to_classes[numero_clase])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7yzVZcZ9-4m"
      },
      "source": [
        "# Conclusión\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline7.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWAReOgo-B7b"
      },
      "source": [
        "Al utilizar más pares de capas CONV+POOL se pudo obtener un mejor resultado, un modelo casi perfecto. Hay que tener en cuenta que el dataset de test es muy pequeño y hay muchos otros personajes que no estamos clasificando."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}